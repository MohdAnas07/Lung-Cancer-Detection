{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ea9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726db6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from codecs import BOM32_BE\n",
    "from ctypes import alignment\n",
    "from unittest import result\n",
    "from xml.dom.expatbuilder import parseString\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import tensorflow._api.v2.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "import pandas as pd\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import messagebox,ttk\n",
    "import tkinter as tk\n",
    "from PIL import Image,ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LCD_CNN:\n",
    "    def __init__(self,root):\n",
    "        self.root=root\n",
    "        #window size\n",
    "        self.root.geometry(\"1006x500+0+0\")\n",
    "        self.root.resizable(False, False)\n",
    "        self.root.title(\"Lung Cancer Detection\")\n",
    "\n",
    "        img4=Image.open(r\"Images\\Lung-Cancer-Detection.jpg\")\n",
    "        img4=img4.resize((1006,500),Image.ANTIALIAS)\n",
    "        #Antialiasing is a technique used in digital imaging to reduce the visual defects that occur when high-resolution images are presented in a lower resolution.\n",
    "        self.photoimg4=ImageTk.PhotoImage(img4)\n",
    "\n",
    "        bg_img=Label(self.root,image=self.photoimg4)\n",
    "        bg_img.place(x=0,y=50,width=1006,height=500)\n",
    "        \n",
    "        # title Label\n",
    "        title_lbl=Label(text=\"Lung Cancer Detection\",font=(\"Bradley Hand ITC\",30,\"bold\"),bg=\"black\",fg=\"white\",)\n",
    "        title_lbl.place(x=0,y=0,width=1006,height=50)\n",
    "\n",
    "        #button 1\n",
    "        self.b1=Button(text=\"Import Data\",cursor=\"hand2\",command=self.import_data,font=(\"Times New Roman\",15,\"bold\"),bg=\"white\",fg=\"black\")\n",
    "        self.b1.place(x=80,y=130,width=180,height=30)\n",
    "\n",
    "        #button 2\n",
    "        self.b2=Button(text=\"Pre-Process Data\",cursor=\"hand2\",command=self.preprocess_data,font=(\"Times New Roman\",15,\"bold\"),bg=\"white\",fg=\"black\")\n",
    "        self.b2.place(x=80,y=180,width=180,height=30)\n",
    "        self.b2[\"state\"] = \"disabled\"\n",
    "        self.b2.config(cursor=\"arrow\")\n",
    "\n",
    "        #button 3\n",
    "        self.b3=Button(text=\"Train Data\",cursor=\"hand2\",command=self.train_data,font=(\"Times New Roman\",15,\"bold\"),bg=\"white\",fg=\"black\")\n",
    "        self.b3.place(x=80,y=230,width=180,height=30)\n",
    "        self.b3[\"state\"] = \"disabled\"\n",
    "        self.b3.config(cursor=\"arrow\")\n",
    "\n",
    "#Data Import lets you upload data from external sources and combine it with data you collect via Analytics.\n",
    "    def import_data(self):\n",
    "        ##Data directory\n",
    "        self.dataDirectory = 'sample_images/'\n",
    "        self.lungPatients = os.listdir(self.dataDirectory)\n",
    "\n",
    "        ##Read labels csv \n",
    "        self.labels = pd.read_csv('stage1_labels.csv', index_col=0)\n",
    "\n",
    "        ##Setting x*y size to 10\n",
    "        self.size = 10\n",
    "\n",
    "        ## Setting z-dimension (number of slices to 5)\n",
    "        self.NoSlices = 5\n",
    "\n",
    "        messagebox.showinfo(\"Import Data\" , \"Data Imported Successfully!\") \n",
    "\n",
    "        self.b1[\"state\"] = \"disabled\"\n",
    "        self.b1.config(cursor=\"arrow\") \n",
    "        self.b2[\"state\"] = \"normal\"\n",
    "        self.b2.config(cursor=\"hand2\")   \n",
    "\n",
    "# Data preprocessing is the process of transforming raw data into an understandable format.\n",
    "    def preprocess_data(self):\n",
    "\n",
    "        def chunks(l, n):\n",
    "            count = 0\n",
    "            for i in range(0, len(l), n):\n",
    "                if (count < self.NoSlices):\n",
    "                    yield l[i:i + n]\n",
    "                    count = count + 1\n",
    "\n",
    "\n",
    "        def mean(l):\n",
    "            return sum(l) / len(l)\n",
    "        #Average\n",
    "\n",
    "\n",
    "        def dataProcessing(patient, labels_df, size=10, noslices=5, visualize=False):\n",
    "            label = labels_df._get_value(patient, 'cancer')\n",
    "            path = self.dataDirectory + patient\n",
    "            slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "            slices.sort(key=lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "            new_slices = []\n",
    "            slices = [cv2.resize(np.array(each_slice.pixel_array), (size, size)) for each_slice in slices]\n",
    "\n",
    "            chunk_sizes = math.floor(len(slices) / noslices)\n",
    "            for slice_chunk in chunks(slices, chunk_sizes):\n",
    "                slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "                new_slices.append(slice_chunk)\n",
    "\n",
    "            if label == 1: #Cancer Patient\n",
    "                label = np.array([0, 1])\n",
    "            elif label == 0:    #Non Cancerous Patient\n",
    "                label = np.array([1, 0])\n",
    "            return np.array(new_slices), label\n",
    "\n",
    "\n",
    "        imageData = []\n",
    "        #Check if Data Labels is available in CSV or not\n",
    "        for num, patient in enumerate(self.lungPatients):\n",
    "            if num % 50 == 0:\n",
    "                print('Saved -', num)\n",
    "            try:\n",
    "                img_data, label = dataProcessing(patient, self.labels, size=self.size, noslices=self.NoSlices)\n",
    "                imageData.append([img_data, label,patient])\n",
    "            except KeyError as e:\n",
    "                print('Data is unlabeled')\n",
    "\n",
    "\n",
    "        ##Results= Image Data and lable.\n",
    "        np.save('imageDataNew-{}-{}-{}.npy'.format(self.size, self.size, self.NoSlices), imageData)\n",
    "\n",
    "        messagebox.showinfo(\"Pre-Process Data\" , \"Data Pre-Processing Done Successfully!\") \n",
    "\n",
    "        self.b2[\"state\"] = \"disabled\"\n",
    "        self.b2.config(cursor=\"arrow\") \n",
    "        self.b3[\"state\"] = \"normal\"\n",
    "        self.b3.config(cursor=\"hand2\")\n",
    "\n",
    "# Data training is the process of training the model based on the dataset and then predict on new data.\n",
    "    def train_data(self):    \n",
    "\n",
    "        imageData = np.load('imageDataNew-10-10-5.npy',allow_pickle=True)\n",
    "        trainingData = imageData[0:42]\n",
    "        validationData = imageData[42:44]\n",
    "\n",
    "        training_data=Label(text=\"Total Training Data: \" + str(len(trainingData)),font=(\"Times New Roman\",13,\"bold\"),bg=\"black\", fg=\"white\",)\n",
    "        training_data.place(x=750,y=150,width=200,height=18)   \n",
    "\n",
    "        validation_data=Label(text=\"Total Validation Data: \" + str(len(validationData)),font=(\"Times New Roman\",13,\"bold\"),bg=\"black\",fg=\"white\",)\n",
    "        validation_data.place(x=750,y=190,width=200,height=18)  \n",
    "\n",
    "        x = tf.placeholder('float')\n",
    "        y = tf.placeholder('float')\n",
    "        size = 10\n",
    "        keep_rate = 0.8\n",
    "        NoSlices = 5\n",
    "\n",
    "        def convolution3d(x, W):\n",
    "            return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "        def maxpooling3d(x):\n",
    "            return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        def cnn(x):\n",
    "            x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
    "            convolution1 = tf.nn.relu(\n",
    "                convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
    "            convolution1 = maxpooling3d(convolution1)\n",
    "            convolution2 = tf.nn.relu(\n",
    "                convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
    "                    tf.random_normal([64])))\n",
    "            convolution2 = maxpooling3d(convolution2)\n",
    "            convolution3 = tf.nn.relu(\n",
    "                convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
    "                    tf.random_normal([128])))\n",
    "            convolution3 = maxpooling3d(convolution3)\n",
    "            convolution4 = tf.nn.relu(\n",
    "                convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
    "                    tf.random_normal([256])))\n",
    "            convolution4 = maxpooling3d(convolution4)\n",
    "            convolution5 = tf.nn.relu(\n",
    "                convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
    "                    tf.random_normal([512])))\n",
    "            convolution5 = maxpooling3d(convolution4)\n",
    "            fullyconnected = tf.reshape(convolution5, [-1, 256])\n",
    "            fullyconnected = tf.nn.relu(\n",
    "                tf.matmul(fullyconnected, tf.Variable(tf.random_normal([256, 256]))) + tf.Variable(tf.random_normal([256])))\n",
    "            fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
    "            output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([256, 2]))) + tf.Variable(tf.random_normal([2]))\n",
    "            return output\n",
    "\n",
    "        def network(x):\n",
    "            prediction = cnn(x)\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "            epochs = 100\n",
    "            with tf.Session() as session:\n",
    "                session.run(tf.global_variables_initializer())\n",
    "                for epoch in range(epochs):\n",
    "                    epoch_loss = 0\n",
    "                    for data in trainingData:\n",
    "                        try:\n",
    "                            X = data[0]\n",
    "                            Y = data[1]\n",
    "                            _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                            epoch_loss += c\n",
    "                        except Exception as e:\n",
    "                            pass\n",
    "                        \n",
    "                    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "                   # if tf.argmax(prediction, 1) == 0:\n",
    "                    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "                    print('Epoch', epoch + 1, 'completed out of', epochs, 'loss:', epoch_loss)\n",
    "                    # print('Correct:',correct.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
    "                    print('Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
    "                #print('Final Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
    "                x1 = accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})\n",
    "\n",
    "                final_accuracy=Label(text=\"Final Accuracy: \" + str(x1),font=(\"Times New Roman\",13,\"bold\"),bg=\"black\", fg=\"white\",)\n",
    "                final_accuracy.place(x=750,y=230,width=200,height=18)  \n",
    "\n",
    "                patients = []\n",
    "                actual = []\n",
    "                predicted = []\n",
    "\n",
    "                finalprediction = tf.argmax(prediction, 1)\n",
    "                actualprediction = tf.argmax(y, 1)\n",
    "                for i in range(len(validationData)):\n",
    "                    patients.append(validationData[i][2])\n",
    "                for i in finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
    "                    if(i==1):\n",
    "                        predicted.append(\"Cancer\")\n",
    "                    else:\n",
    "                        predicted.append(\"No Cancer\")\n",
    "                for i in actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
    "                    if(i==1):\n",
    "                        actual.append(\"Cancer\")\n",
    "                    else:\n",
    "                        actual.append(\"No Cancer\")\n",
    "                for i in range(len(patients)):\n",
    "                    print(\"----------------------------------------------------\")\n",
    "                    print(\"Patient: \",patients[i])\n",
    "                    print(\"Actual: \", actual[i])\n",
    "                    print(\"Predicted: \", predicted[i])\n",
    "                    print(\"----------------------------------------------------\")\n",
    "\n",
    "                # messagebox.showinfo(\"Result\" , \"Patient: \" + ' '.join(map(str,patients)) + \"\\nActual: \" + str(actual) + \"\\nPredicted: \" + str(predicted) + \"Accuracy: \" + str(x1))    \n",
    "\n",
    "                y_actual = pd.Series(\n",
    "                    (actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
    "                    name='Actual')\n",
    "                y_predicted = pd.Series(\n",
    "                    (finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
    "                    name='Predicted')\n",
    "\n",
    "                df_confusion = pd.crosstab(y_actual, y_predicted).reindex(columns=[0,1],index=[0,1], fill_value=0)\n",
    "                print('Confusion Matrix:\\n')\n",
    "                print(df_confusion)\n",
    "\n",
    "                prediction_label=Label(text=\">>>>    P R E D I C T I O N    <<<<\",font=(\"Times New Roman\",14,\"bold\"),bg=\"#778899\", fg=\"black\",)\n",
    "                prediction_label.place(x=0,y=458,width=1006,height=20)   \n",
    "\n",
    "                result1 = []\n",
    "\n",
    "                for i in range(len(validationData)):\n",
    "                    result1.append(patients[i])\n",
    "                    if(y_actual[i] == 1):\n",
    "                        result1.append(\"Cancer\")\n",
    "                    else:\n",
    "                        result1.append(\"No Cancer\")\n",
    "\n",
    "                    if(y_predicted[i] == 1):\n",
    "                        result1.append(\"Cancer\")\n",
    "                    else:\n",
    "                        result1.append(\"No Cancer\")\n",
    "\n",
    "                # print(result1)\n",
    "\n",
    "                total_rows = int(len(patients))\n",
    "                total_columns = int(len(result1)/len(patients))  \n",
    "\n",
    "                heading = [\"Patient: \", \"Actual: \", \"Predicted: \"]\n",
    "\n",
    "                self.root.geometry(\"1006x\"+str(500+(len(patients)*20)-20)+\"+0+0\") \n",
    "                self.root.resizable(False, False)\n",
    "\n",
    "                for i in range(total_rows):\n",
    "                    for j in range(total_columns):\n",
    "                 \n",
    "                        self.e = Entry(root, width=42, fg='black', font=('Times New Roman',12,'bold')) \n",
    "                        self.e.grid(row=i, column=j) \n",
    "                        self.e.place(x=(j*335),y=(478+i*20))\n",
    "                        self.e.insert(END, heading[j] + result1[j + i*3]) \n",
    "                        self.e[\"state\"] = \"disabled\"\n",
    "                        self.e.config(cursor=\"arrow\")                     \n",
    "\n",
    "                self.b3[\"state\"] = \"disabled\"\n",
    "                self.b3.config(cursor=\"arrow\") \n",
    "\n",
    "                messagebox.showinfo(\"Train Data\" , \"Model Trained Successfully!\")\n",
    "\n",
    "                ## Function to plot confusion matrix\n",
    "                def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):\\\n",
    "\n",
    "                    plt.matshow(df_confusion, cmap=cmap)  # imshow  \n",
    "                    # plt.title(title)\n",
    "                    plt.colorbar()\n",
    "                    tick_marks = np.arange(len(df_confusion.columns))\n",
    "                    plt.title(title)\n",
    "                    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "                    plt.yticks(tick_marks, df_confusion.index)\n",
    "                    # plt.tight_layout()\n",
    "                    plt.ylabel(df_confusion.index.name)\n",
    "                    plt.xlabel(df_confusion.columns.name)\n",
    "                    plt.show()\n",
    "                plot_confusion_matrix(df_confusion)\n",
    "                # print(y_true,y_pred)\n",
    "                # print(confusion_matrix(y_true, y_pred))\n",
    "                # print(actualprediction.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
    "                # print(finalprediction.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))  \n",
    "\n",
    "        network(x)\n",
    "\n",
    "# For GUI\n",
    "if __name__ == \"__main__\":\n",
    "        root=Tk()\n",
    "        obj=LCD_CNN(root)\n",
    "        root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62677c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
